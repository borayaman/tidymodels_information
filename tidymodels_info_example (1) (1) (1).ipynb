{"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"},"kernelspec":{"name":"ir","display_name":"R","language":"R"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###Summary\nThe tidy model “verse” is a collection of packages for modelling and statistical analysis that share the underlying design philosophy, grammar, and data structures of the tidyverse.\nThe core packages of tidymodels:\nrsample: for sample splitting\nrecipes: for preprocessing\nparsnip: for specifying the model\nyardstick: for evaluating the model\ntune: for parameter tuning \nworkflows: for putting everything together \nbroom: for converting the information into user-friendly format\ndials: for creating and managing tuning parameters\n###Comparisons\nThere have been debates over R’s consistency problem. The reason behind is that everything is made by different people by using different principles and everything has a slightly different interface. At first, caret was developed to provide a uniform interface for a variety of models in R. It was a great starting point, however, it was slow for even modest size operations compared to tidymodels. Because of the fact that caret is older than tidymodels, there are a lot of resources available for problems about caret. On the other side, tidymodels is newer and is built on the tidyverse principles. Furthermore, caret is a single package consisting of various functions. However, tidymodels has different packages, which give it greater flexibility and possibility to the users. \nCompared to mlr3, tidymodels has greater functionality in the preprocessing step. However, the nested sampling procedure looks more straightforward in mlr3. \nComing to mlflow, it is useful for tracking tidymodels. The tidy model packages integrate greatly with mlfow, which allows automation in the process of tracking.\n###Pros and Cons\nPros:\nIt is flexible. \nIt is faster in general especially compared to caret.\nIt is more tidy in general.\nCons:\nIt is newer, therefore, there are less resources available.\nIt is still in development.\nIt is hard to learn at first because there are lots of specialized packages for each stage.\n###links\nhttps://cran.r-project.org/web/packages/tidymodels/tidymodels.pdf\nhttp://www.rebeccabarter.com/blog/2020-03-25_machine_learning/\nhttps://www.gmudatamining.com/lesson-10-r-tutorial.html\nhttps://towardsdatascience.com/caret-vs-tidymodels-how-to-use-both-packages-together-ee3f85b381c\nhttps://pharmacoecon.me/post/2021-05-01-tidymodels-vs-mlr3/\nhttps://mdneuzerling.com/post/tracking-tidymodels-with-mlflow/","metadata":{}},{"cell_type":"code","source":"library(tidyverse)\nlibrary(tidymodels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datapath <- \"~/data_ad454\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weo_wide2 <- readRDS(sprintf(\"%s/rds/01_01_weo_wide2.rds\", datapath))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weo_countries <- readRDS(sprintf(\"%s/rds/01_01_weo_countries.rds\", datapath))\nweo_subject <- readRDS(sprintf(\"%s/rds/01_01_weo_subject.rds\", datapath))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weo_subject[WEO_Subject_Code == \"NGDP_RPCH\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features<- c(\"NID_NGDP\",\"NGDP_RPCH\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot1<- weo_wide2 %>% filter(year==2019)%>% select(all_of(features)) %>% na.omit()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot1 %>% ggplot(aes(x=NID_NGDP,y=NGDP_RPCH))+\ngeom_point() +\ngeom_smooth(method=\"lm\",formula=y~x,se=F)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set.seed(1000)\n# split the data into trainng (60%) and testing (40%)\ndata_split <- initial_split(plot1, \n                             prop = 3/5)\ndata_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data <- training(data_split)\ntest_data <- testing(data_split)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_model <- linear_reg() %>%\n            set_engine(\"lm\") %>%\n            set_mode(\"regression\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_fit <- lm_model %>% \n          fit(NGDP_RPCH~NID_NGDP, data = train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_fit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names(lm_fit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(lm_fit$fit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"par(mfrow=c(2,2)) # plot all 4 plots in one\n\nplot(lm_fit$fit, \n     pch = 16,    # optional parameters to make points blue\n     col = '#006EA1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tidy(lm_fit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glance(lm_fit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(lm_fit, new_data = test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_results <- predict(lm_fit, new_data = test_data) %>% \n                            bind_cols(test_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RMSE on test set\nrmse(test_results, \n     truth = NGDP_RPCH,\n     estimate = .pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rsq(test_results,\n    truth = NGDP_RPCH,\n    estimate = .pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ggplot(data = test_results,\n       mapping = aes(x = .pred, y = NGDP_RPCH)) +\n  geom_point(color = '#006EA1') +\n  geom_abline(intercept = 0, slope = 1, color = 'orange') +\n  labs(title = 'Linear Regression Results - Test Set',\n       x = 'Predicted',\n       y = 'Actual')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}